{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Remarks: ##Add here"
      ],
      "metadata": {
        "id": "-5tK16CbA5X_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background\n",
        "\n",
        "In digital advertising, Click-Through Rate (CTR) is a critical metric that measures the effectiveness of an advertisement. It is calculated as the ratio of users who click on an ad to the number of users who view the ad. A higher CTR indicates more successful engagement with the audience, which can lead to increased conversions and revenue. From time-to-time advertisers experiment with various elements/targeting of an ad to optimise the ROI."
      ],
      "metadata": {
        "id": "5gLNZ34yH-dO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scenario\n",
        "\n",
        "Imagine an innovative digital advertising agency, AdMasters Inc., that specializes in maximizing click-through rates (CTR) for their clients' advertisements. One of their clients has identified four key tunable elements in their ads: *Age*, *City*, *Gender*, and *Mobile Operating System (OS)*. These elements significantly influence user engagement and conversion rates. The client is keen to optimize their CTR while minimizing resource expenditure."
      ],
      "metadata": {
        "id": "z8nESwkOIE_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective\n",
        "\n",
        "Optimize the CTR of digital ads by employing Multi Arm Bandit algorithms. System should dynamically and efficiently allocate ad displays to maximize overall CTR.\n"
      ],
      "metadata": {
        "id": "I8w5a_8g-ehV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "The dataset for Ads contains 4 unique features/characteristics.\n",
        "*   Age (Range: 25:50)\n",
        "*   City (Possible Values: &#39;New York&#39;, &#39;Los Angeles&#39;, &#39;Chicago&#39;,&#39;Houston&#39;, &#39;Phoenix&#39;)\n",
        "*   Gender (Possible Values: &#39;Male&#39;, &#39;Female&#39;)\n",
        "*   OS: (Possible Values: &#39;iOS&#39;, &#39;Android&#39;, &#39;Other&#39;)\n",
        "\n",
        "***Link for accessing dataset:***\n",
        "https://drive.google.com/file/d/1Y5HmEeoQsafo9Diy9piS69qEMnC0g1ys/view?usp=sharing\n"
      ],
      "metadata": {
        "id": "0v1QvKmDIVoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Details\n",
        "\n",
        "**Arms:** Each arm represents a different ad from the dataset.\n",
        "\n",
        "**Reward Function:**\n",
        "* Probability of a Male clicking on an Ad -> 0.7 (randomly generated)\n",
        "* Probability of a Female clicking on an Ad -> 0.6 (randomly generated)\n",
        "* Once probabilities are assigned to all the values, create a final reward (clicked or not clicked binary outcome) based on the assumed probabilities in step 1 (by combining the probabilities of each feature value present in that ad)\n",
        "\n",
        "**Assumptions**\n",
        "* Assume alpha = beta = 1 for cold start\n",
        "* Explore Percentage = 10%\n",
        "* Run the simulation for min 1000 iterations\n"
      ],
      "metadata": {
        "id": "53dVBXmoL8aF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements and Deliverables:\n",
        "Implement the Multi-Arm Bandit Problem for the given above scenario for all the below mentioned policy methods."
      ],
      "metadata": {
        "id": "Z0whadvHOywr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize constants"
      ],
      "metadata": {
        "id": "Pck-piUAHnmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "\n",
        "epsilon = 0.1\n",
        "\n",
        "# Initialize value function and policy"
      ],
      "metadata": {
        "id": "dgeqZVzXHlQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "Ke_jHsCrQWG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for Dataset loading and print dataset statistics\n",
        "#-----write your code below this line---------\n",
        "\n"
      ],
      "metadata": {
        "id": "FSlqMVeEQa4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Design a CTR Environment (1M)"
      ],
      "metadata": {
        "id": "HroEzPwhQkwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for Dataset loading and print dataset statistics along with reward function\n",
        "#-----write your code below this line---------\n",
        "\n",
        "class CTREnvironment:\n"
      ],
      "metadata": {
        "id": "Uc7EP7ZXQsn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Random Policy (0.5M)\n",
        "Print all the iterations with random policy selected for the given Ad. (Mandatory)"
      ],
      "metadata": {
        "id": "Hvbd8vPwRMBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  run the environment with an agent that is guided by a random policy\n",
        "#-----write your code below this line---------"
      ],
      "metadata": {
        "id": "99WQfj3eROWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Greedy Policy (0.5M)\n",
        "Print all the iterations with random policy selected for the given Ad. (Mandatory)"
      ],
      "metadata": {
        "id": "5t2f1AlERib1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  run the environment with an agent that is guided by a greedy policy\n",
        "#-----write your code below this line---------"
      ],
      "metadata": {
        "id": "TbWz1eCbRib2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Epsilon-Greedy Policy (0.5M)\n",
        "Print all the iterations with random policy selected for the given Ad. (Mandatory)"
      ],
      "metadata": {
        "id": "h65VF2JBRiph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  run the environment with an agent that is guided by a epsilon-greedy policy\n",
        "#-----write your code below this line---------"
      ],
      "metadata": {
        "id": "M6O9odmlRiph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using UCB (0.5M)\n",
        "Print all the iterations with random policy selected for the given Ad. (Mandatory)"
      ],
      "metadata": {
        "id": "yRo-Wi17RiN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  run the environment with an agent that is guided by a UCB\n",
        "#-----write your code below this line---------"
      ],
      "metadata": {
        "id": "Z8nXetCeRiN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot CTR distribution for all the appraoches as a spearate graph (0.5M)"
      ],
      "metadata": {
        "id": "y9QjCw5aIrBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-----write your code below this line---------"
      ],
      "metadata": {
        "id": "J_5XxqPZI2uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changing Exploration Percentage (1M)\n",
        "* How does changing the exploration percentage (EXPLORE_PERCENTAGE) affect the performance of the algorithm? Test with different values (e.g. 0.15 and 0.2) and discuss the results.\n"
      ],
      "metadata": {
        "id": "lf9ssU71H-Rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Implement with any MAB algorithm\n",
        "#Try with different EXPLORE_PERCENTAGE\n",
        "#Different value of alpha"
      ],
      "metadata": {
        "id": "RmzGFSGdH8LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion (0.5M)\n",
        "\n",
        "Conclude your assignment in 250 wrods by discussing the best approach for maximizing the CTR using random, greedy, epsilon-greedy and UCB.\n",
        "\n",
        "`----write below this line------`"
      ],
      "metadata": {
        "id": "xOQk0LcUImEW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jcdGV9-cIqli"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
